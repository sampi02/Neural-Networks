{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Forest Fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = pd.read_csv('C:\\\\Users\\\\User\\\\Documents\\\\Datascience_Assignments\\Assignment 16 (Neural Networks)\\\\forestfires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=forest.drop(['month','day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAE/CAYAAACEto0QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATcklEQVR4nO3df6zd9X3f8debHyNt06wwLsjBLKaRIw2y1HSeGy3VlJZosFStE2mZHG0RkyKZSURr1+wHRJqabvOWSk3z1xLFUVitKQmz1Fag/lopSxdlWnFMRgBDWLxCwAHhm6RZyNbS2rz3x/1SbsiFe/H9XM455vGQrs45n/P9nvu+ErKefL/ne051dwAA2LxzZj0AAMDZQlgBAAwirAAABhFWAACDCCsAgEHOm/UASXLxxRf3jh07Zj0GAMC67r777q9399Jaz81FWO3YsSNHjx6d9RgAAOuqqq++0HNOBQIADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIPMxXcFsrYdN/3WrEdggTzyoZ+a9QgAr3iOWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwyLphVVWvqqojVfWlqjpWVb84rX+wqr5WVfdMP29ftc/NVXW8qh6qqmu38g8AAJgX521gm6eT/GR3f6eqzk/y+ar6nem5j3T3L6/euKquTLIvyVVJXpvk96vqDd19euTgAADzZt0jVr3iO9PD86effpFd9ia5tbuf7u6HkxxPsmfTkwIAzLkNvceqqs6tqnuSnExyR3ffNT31vqq6t6puqaoLp7XLkjy2avcT09rzX3N/VR2tqqPLy8tn/hcAAMyJDYVVd5/u7l1JtifZU1VvTPKxJK9PsivJE0k+PG1ea73EGq95sLt3d/fupaWlMxgdAGC+vKSrArv7W0n+IMl13f3kFFzPJPlEnjvddyLJ5at2257k8c2PCgAw3zZyVeBSVf3QdP/7krwtyZeratuqzd6Z5P7p/u1J9lXVBVV1RZKdSY4MnRoAYA5t5KrAbUkOVdW5WQmxw939m1X1n6pqV1ZO8z2S5IYk6e5jVXU4yQNJTiW50RWBAMArwbph1d33Jrl6jfX3vMg+B5Ic2NxoAACLxSevAwAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAZZN6yq6lVVdaSqvlRVx6rqF6f1i6rqjqr6ynR74ap9bq6q41X1UFVdu5V/AADAvNjIEaunk/xkd/9Ikl1JrquqNye5Kcmd3b0zyZ3T41TVlUn2JbkqyXVJPlpV527B7AAAc2XdsOoV35kenj/9dJK9SQ5N64eSvGO6vzfJrd39dHc/nOR4kj0jhwYAmEcbeo9VVZ1bVfckOZnkju6+K8ml3f1Ekky3l0ybX5bksVW7n5jWnv+a+6vqaFUdXV5e3sSfAAAwHzYUVt19urt3JdmeZE9VvfFFNq+1XmKN1zzY3bu7e/fS0tKGhgUAmGcv6arA7v5Wkj/IynunnqyqbUky3Z6cNjuR5PJVu21P8vhmBwUAmHcbuSpwqap+aLr/fUneluTLSW5Pcv202fVJbpvu355kX1VdUFVXJNmZ5MjguQEA5s55G9hmW5JD05V95yQ53N2/WVX/I8nhqnpvkkeTvCtJuvtYVR1O8kCSU0lu7O7TWzM+AMD8WDesuvveJFevsf6NJNe8wD4HkhzY9HQAAAvEJ68DAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAyyblhV1eVV9dmqerCqjlXVz07rH6yqr1XVPdPP21ftc3NVHa+qh6rq2q38AwAA5sV5G9jmVJL3d/cXq+oHk9xdVXdMz32ku3959cZVdWWSfUmuSvLaJL9fVW/o7tMjBwcAmDfrHrHq7ie6+4vT/aeSPJjkshfZZW+SW7v76e5+OMnxJHtGDAsAMM9e0nusqmpHkquT3DUtva+q7q2qW6rqwmntsiSPrdrtRNYIsaraX1VHq+ro8vLyS58cAGDObDisqurVSX4tyc9197eTfCzJ65PsSvJEkg8/u+kau/f3LHQf7O7d3b17aWnppc4NADB3NhRWVXV+VqLqU93960nS3U929+nufibJJ/Lc6b4TSS5ftfv2JI+PGxkAYD5t5KrASvLJJA9296+sWt+2arN3Jrl/un97kn1VdUFVXZFkZ5Ij40YGAJhPG7kq8C1J3pPkvqq6Z1r7QJJ3V9WurJzmeyTJDUnS3ceq6nCSB7JyReGNrggEAF4J1g2r7v581n7f1G+/yD4HkhzYxFwAAAvHJ68DAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAyyblhV1eVV9dmqerCqjlXVz07rF1XVHVX1len2wlX73FxVx6vqoaq6div/AACAebGRI1ankry/u/9akjcnubGqrkxyU5I7u3tnkjunx5me25fkqiTXJfloVZ27FcMDAMyTdcOqu5/o7i9O959K8mCSy5LsTXJo2uxQkndM9/cmubW7n+7uh5McT7Jn8NwAAHPnJb3Hqqp2JLk6yV1JLu3uJ5KV+EpyybTZZUkeW7XbiWnt+a+1v6qOVtXR5eXlMxgdAGC+bDisqurVSX4tyc9197dfbNM11vp7FroPdvfu7t69tLS00TEAAObWhsKqqs7PSlR9qrt/fVp+sqq2Tc9vS3JyWj+R5PJVu29P8viYcQEA5tdGrgqsJJ9M8mB3/8qqp25Pcv10//okt61a31dVF1TVFUl2JjkybmQAgPl03ga2eUuS9yS5r6rumdY+kORDSQ5X1XuTPJrkXUnS3ceq6nCSB7JyReGN3X169OAAAPNm3bDq7s9n7fdNJck1L7DPgSQHNjEXAMDC8cnrAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDCCsAgEGEFQDAIMIKAGAQYQUAMIiwAgAYRFgBAAwirAAABhFWAACDrBtWVXVLVZ2sqvtXrX2wqr5WVfdMP29f9dzNVXW8qh6qqmu3anAAgHmzkSNWv5rkujXWP9Ldu6af306Sqroyyb4kV037fLSqzh01LADAPFs3rLr7c0m+ucHX25vk1u5+ursfTnI8yZ5NzAcAsDA28x6r91XVvdOpwguntcuSPLZqmxPT2veoqv1VdbSqji4vL29iDACA+XCmYfWxJK9PsivJE0k+PK3XGtv2Wi/Q3Qe7e3d3715aWjrDMQAA5scZhVV3P9ndp7v7mSSfyHOn+04kuXzVptuTPL65EQEAFsMZhVVVbVv18J1Jnr1i8PYk+6rqgqq6IsnOJEc2NyIAwGI4b70NquozSd6a5OKqOpHkF5K8tap2ZeU03yNJbkiS7j5WVYeTPJDkVJIbu/v0lkwOADBn1g2r7n73GsuffJHtDyQ5sJmhAAAWkU9eBwAYRFgBAAyy7qlAAM4uO276rVmPwAJ55EM/NesRFoojVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMsm5YVdUtVXWyqu5ftXZRVd1RVV+Zbi9c9dzNVXW8qh6qqmu3anAAgHmzkSNWv5rkuuet3ZTkzu7emeTO6XGq6sok+5JcNe3z0ao6d9i0AABzbN2w6u7PJfnm85b3Jjk03T+U5B2r1m/t7qe7++Ekx5PsGTMqAMB8O9P3WF3a3U8kyXR7ybR+WZLHVm13Ylr7HlW1v6qOVtXR5eXlMxwDAGB+jH7zeq2x1mtt2N0Hu3t3d+9eWloaPAYAwMvvTMPqyaraliTT7clp/USSy1dttz3J42c+HgDA4jjTsLo9yfXT/euT3LZqfV9VXVBVVyTZmeTI5kYEAFgM5623QVV9Jslbk1xcVSeS/EKSDyU5XFXvTfJoknclSXcfq6rDSR5IcirJjd19eotmBwCYK+uGVXe/+wWeuuYFtj+Q5MBmhgIAWEQ+eR0AYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYBBhBQAwiLACABhEWAEADCKsAAAGEVYAAIMIKwCAQYQVAMAgwgoAYJDzNrNzVT2S5Kkkp5Oc6u7dVXVRkv+cZEeSR5L8/e7+482NCQAw/0YcsfqJ7t7V3bunxzclubO7dya5c3oMAHDW24pTgXuTHJruH0ryji34HQAAc2ezYdVJfq+q7q6q/dPapd39RJJMt5estWNV7a+qo1V1dHl5eZNjAADM3qbeY5XkLd39eFVdkuSOqvryRnfs7oNJDibJ7t27e5NzAADM3KaOWHX349PtySS/kWRPkieraluSTLcnNzskAMAiOOOwqqofqKoffPZ+kr+T5P4ktye5ftrs+iS3bXZIAIBFsJlTgZcm+Y2qevZ1Pt3dv1tVX0hyuKrem+TRJO/a/JgAAPPvjMOqu/8oyY+ssf6NJNdsZigAgEXkk9cBAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAYRVgAAgwgrAIBBhBUAwCDCCgBgEGEFADCIsAIAGERYAQAMIqwAAAbZsrCqquuq6qGqOl5VN23V7wEAmBdbElZVdW6S/5Dk7ya5Msm7q+rKrfhdAADzYquOWO1Jcry7/6i7/yzJrUn2btHvAgCYC+dt0eteluSxVY9PJPmx1RtU1f4k+6eH36mqh7ZoFs4+Fyf5+qyHmDf1S7OeABaef1vW4N+WNb3uhZ7YqrCqNdb6ux50H0xycIt+P2exqjra3btnPQdwdvFvCyNs1anAE0kuX/V4e5LHt+h3AQDMha0Kqy8k2VlVV1TVX0qyL8ntW/S7AADmwpacCuzuU1X1viT/Jcm5SW7p7mNb8bt4RXIKGdgK/m1h06q7198KAIB1+eR1AIBBhBUAwCDCCgBgEGEFADCIsAIAGGSrPnkdNq2q7svzPrH/2aeSdHe/6WUeCTjLVNUbknwsyaXd/caqelOSn+nufzvj0VhQPm6BuVVVL/hdTEnS3V99uWYBzk5V9d+S/PMkH+/uq6e1+7v7jbOdjEXliBVzSzgBL4Pv7+4jVd/1FbenZjUMi09YMbeq6qm8+KnA17zMIwFnn69X1esz/VtTVX8vyROzHYlF5lQgAK9YVfXDWfkqm7+V5I+TPJzkH3b3I7Oci8UlrFgYVXVJklc9+7i7H53hOMBZpKp+IMk53f3UrGdhsTkVyNyrqp9J8uEkr01yMsnrkjyY5KpZzgUsvqr6+ec9TpL/k+Tu7r5nFjOx2HyOFYvg3yR5c5L/1d1XJLkmyX+f7UjAWWJ3kn+c5LLpZ3+Styb5RFX9ixnOxYISViyCP+/ubyQ5p6rO6e7PJtk145mAs8NfSfKj3f3+7n5/VkJrKcnfTvKPZjkYi8mpQBbBt6rq1Uk+l+RTVXUyLocGxvirSf5s1eM/T/K67v6Tqnp6RjOxwIQVi2Bvkj9N8k+T/IMkfznJv57pRMDZ4tNJ/rCqbpse/3SSz0xvZn9gdmOxqFwVyMKoqtdk1f8MdPc3ZzgOsOBq5Z3q25NckuTHs/IZeZ/v7qMzHYyFJqyYe1V1Q1aOUP1Jkmfy3AeE/vBMBwMWXlXd3d1/Y9ZzcPZwKpBF8M+SXNXdX5/1IMBZ5w+r6m929xdmPQhnB2HFIvjfSf7frIcAzko/keSGqvpqkv+b546Iv2m2Y7GonApk7lXV1Un+Y5K7kvzFVTrd/U9mNhRwVqiq16217kvgOVOOWLEIPp7kvya5LyvvsQIY4tmAev5XZsGZElYsglPd/fPrbwbw0vjKLEbzyessgs9W1f6q2lZVFz37M+uhgLOCr8xiKO+xYu5V1cOrHv7Ff7A+bgHYrKo62t27q+pLSa7u7meq6kh375n1bCwmpwJZBP8yye9297er6l8l+dGs/F8mwGb5yiyGcsSKuVdV93b3m6rqx5P8u6y8H+ID3f1jMx4NWHDTV9f8aVY+ZuHZr8z61PTF7/CSCSvmXlX9z+6+uqr+fZL7uvvTz67NejYAWM2pQBbB16rq40neluSXquqCuPAC2ISqeiqr3rO5+qmsfEDoa17mkThLOGLF3Kuq709yXVaOVn2lqrYl+evd/XszHg0AvouwAgAYxOkUAIBBhBUAwCDCCgBgEGEFADDI/weITn6grzGlvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "forest.size_category.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lable_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest['size_category'] = lable_encoder.fit_transform(forest.size_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthfeb  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0              1  \n",
       "1         0              1  \n",
       "2         0              1  \n",
       "3         0              1  \n",
       "4         0              1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_array= forest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = f_array[:,0:28]\n",
    "Y = f_array[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.752306e-15</td>\n",
       "      <td>-2.748715e-17</td>\n",
       "      <td>6.871787e-17</td>\n",
       "      <td>1.030768e-17</td>\n",
       "      <td>2.542561e-16</td>\n",
       "      <td>2.198972e-16</td>\n",
       "      <td>-4.191790e-16</td>\n",
       "      <td>-6.871787e-18</td>\n",
       "      <td>4.123072e-17</td>\n",
       "      <td>3.435893e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.871787e-17</td>\n",
       "      <td>2.061536e-17</td>\n",
       "      <td>2.233331e-17</td>\n",
       "      <td>-1.374357e-17</td>\n",
       "      <td>-1.374357e-17</td>\n",
       "      <td>-8.246144e-17</td>\n",
       "      <td>-1.717947e-17</td>\n",
       "      <td>-1.030768e-17</td>\n",
       "      <td>5.497429e-17</td>\n",
       "      <td>2.748715e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.304582e+01</td>\n",
       "      <td>-1.715608e+00</td>\n",
       "      <td>-2.179108e+00</td>\n",
       "      <td>-1.980578e+00</td>\n",
       "      <td>-2.876943e+00</td>\n",
       "      <td>-1.796637e+00</td>\n",
       "      <td>-2.021098e+00</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.063453e-02</td>\n",
       "      <td>-6.606652e-01</td>\n",
       "      <td>-4.448281e-01</td>\n",
       "      <td>-5.535954e-01</td>\n",
       "      <td>-5.842379e-01</td>\n",
       "      <td>-6.924563e-01</td>\n",
       "      <td>-7.361236e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.732292e-01</td>\n",
       "      <td>-4.020255e-02</td>\n",
       "      <td>4.691190e-01</td>\n",
       "      <td>-1.364774e-01</td>\n",
       "      <td>7.082076e-02</td>\n",
       "      <td>-1.403660e-01</td>\n",
       "      <td>-9.833712e-03</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-1.938429e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.089598e-01</td>\n",
       "      <td>4.927389e-01</td>\n",
       "      <td>6.696628e-01</td>\n",
       "      <td>3.904086e-01</td>\n",
       "      <td>6.741643e-01</td>\n",
       "      <td>5.344111e-01</td>\n",
       "      <td>4.929823e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-9.870852e-02</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.007353e+00</td>\n",
       "      <td>2.819865e+00</td>\n",
       "      <td>1.261610e+00</td>\n",
       "      <td>1.033538e+01</td>\n",
       "      <td>2.484195e+00</td>\n",
       "      <td>3.417549e+00</td>\n",
       "      <td>3.007063e+00</td>\n",
       "      <td>2.157228e+01</td>\n",
       "      <td>1.695111e+01</td>\n",
       "      <td>2.254407e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -1.752306e-15 -2.748715e-17  6.871787e-17  1.030768e-17  2.542561e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.304582e+01 -1.715608e+00 -2.179108e+00 -1.980578e+00 -2.876943e+00   \n",
       "25%   -8.063453e-02 -6.606652e-01 -4.448281e-01 -5.535954e-01 -5.842379e-01   \n",
       "50%    1.732292e-01 -4.020255e-02  4.691190e-01 -1.364774e-01  7.082076e-02   \n",
       "75%    4.089598e-01  4.927389e-01  6.696628e-01  3.904086e-01  6.741643e-01   \n",
       "max    1.007353e+00  2.819865e+00  1.261610e+00  1.033538e+01  2.484195e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   2.198972e-16 -4.191790e-16 -6.871787e-18  4.123072e-17  3.435893e-18   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.796637e+00 -2.021098e+00 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "25%   -6.924563e-01 -7.361236e-01 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "50%   -1.403660e-01 -9.833712e-03 -7.326831e-02 -1.938429e-01 -4.435755e-01   \n",
       "75%    5.344111e-01  4.929823e-01 -7.326831e-02 -9.870852e-02 -4.435755e-01   \n",
       "max    3.417549e+00  3.007063e+00  2.157228e+01  1.695111e+01  2.254407e+00   \n",
       "\n",
       "       ...            18            19            20            21  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ... -6.871787e-17  2.061536e-17  2.233331e-17 -1.374357e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 22            23            24            25            26  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -1.374357e-17 -8.246144e-17 -1.717947e-17 -1.030768e-17  5.497429e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 27  \n",
       "count  5.170000e+02  \n",
       "mean   2.748715e-17  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10,20]\n",
    "epochs = [10,30]\n",
    "learning_rate = [0.001,0.1]\n",
    "dropout_rate = [0.0,0.1]\n",
    "activation_function = ['softmax','relu']\n",
    "init = ['normal']\n",
    "neuron1 = [4,8]\n",
    "neuron2 = [2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "[CV 1/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 2/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 3/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.2s\n",
      "[CV 4/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 1/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.0s\n",
      "[CV 2/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 3/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.2s\n",
      "[CV 1/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 2/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 3/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 4/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.2s\n",
      "[CV 5/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 1/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 2/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   3.3s\n",
      "[CV 4/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 5/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 2/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.5s\n",
      "[CV 3/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.6s\n",
      "[CV 4/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 5/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 1/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.8s\n",
      "[CV 2/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.0s\n",
      "[CV 3/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.3s\n",
      "[CV 4/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 5/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 1/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   3.4s\n",
      "[CV 2/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 3/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 4/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   3.1s\n",
      "[CV 1/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 2/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.4s\n",
      "[CV 4/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.8s\n",
      "[CV 5/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 1/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.1s\n",
      "[CV 2/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.2s\n",
      "[CV 3/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 4/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.1s\n",
      "[CV 5/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.5s\n",
      "[CV 1/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.9s\n",
      "[CV 3/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 4/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.7s\n",
      "[CV 5/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 1/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.8s\n",
      "[CV 2/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 3/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 4/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.8s\n",
      "[CV 5/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.7s\n",
      "[CV 1/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 2/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.3s\n",
      "[CV 3/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.6s\n",
      "[CV 4/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 5/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.5s\n",
      "[CV 1/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.4s\n",
      "[CV 2/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 3/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.5s\n",
      "[CV 4/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.7s\n",
      "[CV 5/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.2s\n",
      "[CV 1/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 2/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.9s\n",
      "[CV 3/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.4s\n",
      "[CV 4/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.2s\n",
      "[CV 5/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.1s\n",
      "[CV 1/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.2s\n",
      "[CV 2/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 3/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.5s\n",
      "[CV 4/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 5/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.8s\n",
      "[CV 1/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.7s\n",
      "[CV 2/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.2s\n",
      "[CV 3/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 4/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.5s\n",
      "[CV 5/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.6s\n",
      "[CV 1/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 2/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.2s\n",
      "[CV 3/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 4/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   3.9s\n",
      "[CV 1/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 3/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 4/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 1/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 2/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 3/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 4/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 5/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.3s\n",
      "[CV 1/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.7s\n",
      "[CV 4/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 5/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.1s\n",
      "[CV 1/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 2/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 3/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.2s\n",
      "[CV 4/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 5/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 1/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 2/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 3/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.3s\n",
      "[CV 5/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 1/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 2/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 3/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 4/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 5/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 1/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 2/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 3/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 4/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 5/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   2.6s\n",
      "[CV 1/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 2/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.6s\n",
      "[CV 3/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 4/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.8s\n",
      "[CV 5/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.5s\n",
      "[CV 1/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.7s\n",
      "[CV 2/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 3/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 4/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.6s\n",
      "[CV 5/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.7s\n",
      "[CV 1/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.7s\n",
      "[CV 2/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   6.0s\n",
      "[CV 3/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   6.4s\n",
      "[CV 4/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 5/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.9s\n",
      "[CV 1/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.8s\n",
      "[CV 2/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 3/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.1s\n",
      "[CV 4/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.8s\n",
      "[CV 5/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.1s\n",
      "[CV 1/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 2/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.6s\n",
      "[CV 3/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.7s\n",
      "[CV 4/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.3s\n",
      "[CV 5/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.6s\n",
      "[CV 1/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.7s\n",
      "[CV 2/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.4s\n",
      "[CV 3/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.3s\n",
      "[CV 4/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.4s\n",
      "[CV 5/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   7.0s\n",
      "[CV 1/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.2s\n",
      "[CV 2/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.9s\n",
      "[CV 3/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.0s\n",
      "[CV 4/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.9s\n",
      "[CV 5/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.8s\n",
      "[CV 1/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.1s\n",
      "[CV 2/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.8s\n",
      "[CV 3/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 4/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.1s\n",
      "[CV 5/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.7s\n",
      "[CV 1/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 2/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   2.9s\n",
      "[CV 3/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   3.5s\n",
      "[CV 4/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 5/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 1/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 2/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 4/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 5/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 1/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.0s\n",
      "[CV 2/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.1s\n",
      "[CV 3/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 4/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 5/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.0s\n",
      "[CV 1/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 3/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 5/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.1s\n",
      "[CV 2/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.2s\n",
      "[CV 3/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 4/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.6s\n",
      "[CV 5/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 1/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 2/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 3/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 4/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 5/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.4s\n",
      "[CV 1/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 2/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 3/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 4/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 1/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.4s\n",
      "[CV 3/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 4/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.4s\n",
      "[CV 5/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.6s\n",
      "[CV 1/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 2/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 3/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.0s\n",
      "[CV 4/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 5/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 1/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.9s\n",
      "[CV 2/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.2s\n",
      "[CV 1/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.1s\n",
      "[CV 2/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 3/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 4/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.1s\n",
      "[CV 5/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.6s\n",
      "[CV 1/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.6s\n",
      "[CV 2/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 4/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.2s\n",
      "[CV 1/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 2/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 3/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.4s\n",
      "[CV 4/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 5/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 1/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.2s\n",
      "[CV 2/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 3/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 4/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.9s\n",
      "[CV 5/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.1s\n",
      "[CV 1/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   3.5s\n",
      "[CV 2/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 3/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.2s\n",
      "[CV 4/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 5/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 1/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.2s\n",
      "[CV 2/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.1s\n",
      "[CV 3/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.2s\n",
      "[CV 5/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 1/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 2/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.5s\n",
      "[CV 3/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 4/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 5/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.5s\n",
      "[CV 1/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 2/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 3/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   2.9s\n",
      "[CV 4/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 1/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.4s\n",
      "[CV 2/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 3/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 4/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 5/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 1/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 2/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 3/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.4s\n",
      "[CV 4/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 2/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 3/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.5s\n",
      "[CV 4/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 5/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 1/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 2/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 3/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 4/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 5/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 1/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 2/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 3/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.4s\n",
      "[CV 4/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 1/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.1s\n",
      "[CV 2/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.1s\n",
      "[CV 3/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 4/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 5/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 1/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.3s\n",
      "[CV 2/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 3/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 4/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.0s\n",
      "[CV 5/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 1/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 2/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 3/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.5s\n",
      "[CV 4/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 1/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.2s\n",
      "[CV 2/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 3/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 4/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.2s\n",
      "[CV 5/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 1/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.3s\n",
      "[CV 2/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.3s\n",
      "[CV 3/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 4/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 2/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 3/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 4/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.4s\n",
      "[CV 5/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 1/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.9s\n",
      "[CV 2/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 4/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.1s\n",
      "[CV 1/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 2/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 3/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.6s\n",
      "[CV 4/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.6s\n",
      "[CV 2/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 4/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 5/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 1/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.9s\n",
      "[CV 2/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.5s\n",
      "[CV 3/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.5s\n",
      "[CV 4/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 2/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 3/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 4/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 5/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.2s\n",
      "[CV 1/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 2/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.8s\n",
      "[CV 3/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.7s\n",
      "[CV 4/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.7s\n",
      "[CV 2/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 4/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.4s\n",
      "[CV 5/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 1/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 2/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 3/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 4/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 2/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.2s\n",
      "[CV 3/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.2s\n",
      "[CV 4/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 5/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 1/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 2/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 3/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 4/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.5s\n",
      "[CV 2/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 3/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 4/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 5/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 1/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.1s\n",
      "[CV 2/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.7s\n",
      "[CV 3/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.7s\n",
      "[CV 4/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.5s\n",
      "[CV 5/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.5s\n",
      "[CV 1/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.7s\n",
      "[CV 2/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.5s\n",
      "[CV 3/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 4/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.5s\n",
      "[CV 5/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 1/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.7s\n",
      "[CV 2/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 3/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 4/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 5/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   7.0s\n",
      "[CV 1/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 2/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.5s\n",
      "[CV 3/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.6s\n",
      "[CV 4/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.5s\n",
      "[CV 5/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 1/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.5s\n",
      "[CV 2/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.9s\n",
      "[CV 3/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.2s\n",
      "[CV 4/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.7s\n",
      "[CV 5/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   8.4s\n",
      "[CV 1/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.1s\n",
      "[CV 2/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.3s\n",
      "[CV 3/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   7.0s\n",
      "[CV 4/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.4s\n",
      "[CV 5/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 1/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 2/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.7s\n",
      "[CV 3/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.3s\n",
      "[CV 4/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.7s\n",
      "[CV 5/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.3s\n",
      "[CV 1/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.5s\n",
      "[CV 2/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.0s\n",
      "[CV 3/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   6.0s\n",
      "[CV 4/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 5/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.7s\n",
      "[CV 1/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 2/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 3/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 4/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 5/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.0s\n",
      "[CV 1/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 2/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 3/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 4/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 5/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 1/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.1s\n",
      "[CV 2/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 3/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 4/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   6.3s\n",
      "[CV 1/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 2/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 4/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 5/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.7s\n",
      "[CV 1/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 2/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 3/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 4/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   6.1s\n",
      "[CV 1/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 2/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 3/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.8s\n",
      "[CV 4/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.0s\n",
      "[CV 5/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 2/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 3/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 4/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 5/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   6.4s\n",
      "[CV 1/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 2/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 3/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.7s\n",
      "[CV 4/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 5/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 1/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.3s\n",
      "[CV 2/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.9s\n",
      "[CV 3/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 4/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 5/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 1/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.6s\n",
      "[CV 2/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 3/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.9s\n",
      "[CV 4/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 5/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.6s\n",
      "[CV 1/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.9s\n",
      "[CV 2/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 3/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 4/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.9s\n",
      "[CV 5/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 1/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.7s\n",
      "[CV 2/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   7.8s\n",
      "[CV 3/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.8s\n",
      "[CV 4/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 5/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.1s\n",
      "[CV 1/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 2/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 3/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 4/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.4s\n",
      "[CV 5/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.8s\n",
      "[CV 1/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.7s\n",
      "[CV 2/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   8.0s\n",
      "[CV 3/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 4/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 5/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.8s\n",
      "[CV 1/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 2/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.6s\n",
      "[CV 3/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.8s\n",
      "[CV 4/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.5s\n",
      "[CV 5/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 1/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.6s\n",
      "[CV 2/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.9s\n",
      "[CV 3/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   7.8s\n",
      "[CV 4/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.4s\n",
      "[CV 5/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.3s\n",
      "[CV 1/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 2/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   3.9s\n",
      "[CV 3/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 4/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.0s\n",
      "[CV 5/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 1/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 2/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 3/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 4/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   6.3s\n",
      "[CV 1/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.9s\n",
      "[CV 2/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 3/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.4s\n",
      "[CV 4/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.1s\n",
      "[CV 5/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.0s\n",
      "[CV 1/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.2s\n",
      "[CV 2/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.1s\n",
      "[CV 3/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 4/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 5/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.2s\n",
      "[CV 1/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.9s\n",
      "[CV 2/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.0s\n",
      "[CV 3/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 4/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 5/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.3s\n",
      "[CV 1/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 2/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 3/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 4/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 5/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.9s\n",
      "[CV 1/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 2/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.0s\n",
      "[CV 3/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 4/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 5/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 1/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 2/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.2s\n",
      "[CV 3/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 4/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.3s\n",
      "[CV 5/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 1/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 2/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 3/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.6s\n",
      "[CV 4/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   7.1s\n",
      "[CV 1/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 2/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 4/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.9s\n",
      "[CV 5/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 1/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 2/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 3/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 4/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.6s\n",
      "[CV 5/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 1/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 2/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 3/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   7.1s\n",
      "[CV 4/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.5s\n",
      "[CV 5/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.6s\n",
      "[CV 1/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 2/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.1s\n",
      "[CV 3/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 4/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.2s\n",
      "[CV 5/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 1/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 2/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.5s\n",
      "[CV 3/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   3.6s\n",
      "[CV 4/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 5/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.9s\n",
      "[CV 1/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 2/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 3/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 4/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.1s\n",
      "[CV 5/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 1/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 2/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 3/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 4/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 1/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 2/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.0s\n",
      "[CV 3/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.4s\n",
      "[CV 4/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   3.7s\n",
      "[CV 5/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   2.8s\n",
      "[CV 1/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 2/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 3/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 4/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 5/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 1/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 2/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.2s\n",
      "[CV 3/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   3.9s\n",
      "[CV 4/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.4s\n",
      "[CV 5/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.3s\n",
      "[CV 1/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   6.3s\n",
      "[CV 2/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 3/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.2s\n",
      "[CV 4/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 5/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.4s\n",
      "[CV 1/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 2/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.2s\n",
      "[CV 3/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.0s\n",
      "[CV 4/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.3s\n",
      "[CV 5/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   3.2s\n",
      "[CV 1/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.2s\n",
      "[CV 2/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.1s\n",
      "[CV 3/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.0s\n",
      "[CV 4/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   6.3s\n",
      "[CV 5/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.3s\n",
      "[CV 1/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.0s\n",
      "[CV 2/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   3.9s\n",
      "[CV 3/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 4/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.5s\n",
      "[CV 5/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.1s\n",
      "[CV 1/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 2/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.2s\n",
      "[CV 3/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 4/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 5/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.9s\n",
      "[CV 1/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.9s\n",
      "[CV 2/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   6.9s\n",
      "[CV 3/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   3.6s\n",
      "[CV 4/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.1s\n",
      "[CV 5/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 1/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.7s\n",
      "[CV 2/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.1s\n",
      "[CV 3/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 4/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 5/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 1/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 2/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 3/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   4.8s\n",
      "[CV 4/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   5.1s\n",
      "[CV 5/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2; total time=   7.1s\n",
      "[CV 1/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 2/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 3/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.9s\n",
      "[CV 4/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   5.4s\n",
      "[CV 5/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4; total time=   4.0s\n",
      "[CV 1/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 2/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 3/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   5.0s\n",
      "[CV 4/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.8s\n",
      "[CV 5/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2; total time=   4.7s\n",
      "[CV 1/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.8s\n",
      "[CV 2/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.9s\n",
      "[CV 3/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   4.6s\n",
      "[CV 4/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   7.6s\n",
      "[CV 5/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4; total time=   5.0s\n",
      "[CV 1/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 2/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   5.0s\n",
      "[CV 3/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 4/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.7s\n",
      "[CV 5/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2; total time=   4.9s\n",
      "[CV 1/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.7s\n",
      "[CV 2/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   3.3s\n",
      "[CV 3/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.8s\n",
      "[CV 4/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   5.0s\n",
      "[CV 5/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4; total time=   4.7s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8741784930229187, using {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.650970870256424,0.232809376585483 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8101381540298462,0.09706168034111773 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7751867175102234,0.15126760626813346 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7581777334213257,0.01678725808959428 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7539394974708558,0.11522273770267337 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8158326983451843,0.10626009647573491 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8392457127571106,0.08294593959133718 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7229462385177612,0.12340040768985679 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7522031307220459,0.07267613592218133 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.5305825233459472,0.2757845556417363 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7307878971099854,0.14304549311509016 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7250933527946473,0.10387211710279784 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7193987965583801,0.04936501170214746 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.6922703504562377,0.0852853053449289 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7443054556846619,0.13246272748210136 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8430732011795044,0.09043245948479246 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7462658643722534,0.09207929081917611 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.726773715019226,0.13044185953490992 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.650970870256424,0.232809376585483 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.5305825233459472,0.2757845556417363 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8023898482322693,0.10085701399241881 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7577109694480896,0.13367298144292455 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8160007476806641,0.08362174414417128 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7811613321304322,0.08682046093345148 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.843091857433319,0.10008650011543371 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8450522780418396,0.060017827201598324 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8295183062553406,0.07926920777615981 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8315160632133484,0.07423603596298672 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.4587378680706024,0.27438996059348447 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.752091109752655,0.1221509863150949 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7598767876625061,0.09948325160794548 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7266990303993225,0.15582146233340108 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7364451050758362,0.14016281522007787 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8277259111404419,0.08625850735588528 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8316094040870666,0.04044118377209776 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.802352511882782,0.1023213257090221 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8179238319396973,0.09437398730280061 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7286781191825866,0.14711530275065407 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7674757242202759,0.11851422842004461 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7674757361412048,0.11819565511175724 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8024271845817565,0.10692402462109002 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8277445673942566,0.10809525771296428 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8121732711791992,0.0986875484023137 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8392643809318543,0.09099842645450337 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8567027688026428,0.07321299415605649 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8235250115394592,0.12003089842801729 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7382748365402222,0.14916950714211769 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7383121848106384,0.15384151134789484 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7479462265968323,0.15560276521593006 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.734466016292572,0.1537509780062806 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7286781191825866,0.14711530275065407 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7364077568054199,0.15359763543603858 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.736351752281189,0.1555033618237364 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7441747546195984,0.15396540272278342 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7887976050376893,0.1533751473245604 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7422330141067505,0.15224774392940219 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8004294395446777,0.10173532032483938 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8411687970161438,0.08545618368301505 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7616504788398742,0.1550087481034069 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7694174647331238,0.16554750221289766 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7325055956840515,0.15464018573921784 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7364077687263488,0.15285944434968482 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7325242757797241,0.15178268966445949 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7577109813690186,0.15356533261149222 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8061426520347595,0.11095197490998673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8002800583839417,0.1545387115106042 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7887789368629455,0.12896978757410874 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7636295676231384,0.11044038395645943 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7423076868057251,0.1388916753254261 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7537901520729064,0.14718116660125652 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7365011215209961,0.13672313394249724 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7981889486312866,0.17031357945735123 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8545929789543152,0.17020516697776797 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7985436916351318,0.15847860477652143 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8741784930229187,0.022534206388782396 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7325242757797241,0.15178268966445949 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7402912616729737,0.15358536146170676 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7212098479270935,0.11255397067558444 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7674197077751159,0.15255275514744687 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7616504788398742,0.1301514206532466 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7383495092391967,0.15354239422184465 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7422330141067505,0.15224774392940219 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7403472781181335,0.14180215020448053 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7849701285362244,0.11165951186073074 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8585324883460999,0.10081216577444492 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7749626636505127,0.16244505896952002 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7558439135551452,0.1553952968988436 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best : 0.8741784930229187, using {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model1.add(Dropout(0.0))\n",
    "    model1.add(Dense(4,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model1.add(Dropout(0.0))\n",
    "    model1.add(Dense(1,activation = 'sigmoid'))\n",
    "    adam = Adam(lr = 0.1)\n",
    "    model1.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9fbfe0370>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sagar\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "Y_predict = model1.predict(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9458413926499033\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y,Y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
